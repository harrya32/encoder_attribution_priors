{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3XPm3DUU3yGb","outputId":"b34d6f4a-c038-413a-9a5d-94e5e9197c34"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: captum in /usr/local/lib/python3.10/dist-packages (0.7.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum) (1.23.5)\n","Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum) (2.1.0+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from captum) (4.66.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2.1.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.46.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->captum) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->captum) (1.3.0)\n"]}],"source":["!pip install captum\n","%pip install 'drive/MyDrive/encoder_attribution_priors/.'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z5BzCW00v06E"},"outputs":[],"source":["import argparse\n","import csv\n","import itertools\n","import logging\n","import os\n","from pathlib import Path\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import torch\n","import torchvision\n","from captum.attr import GradientShap, IntegratedGradients, Saliency\n","from scipy.stats import spearmanr\n","from torch.utils.data import DataLoader, RandomSampler, Subset\n","from torchvision import transforms\n","\n","from lfxai.explanations.examples import (\n","    InfluenceFunctions,\n","    NearestNeighbours,\n","    SimplEx,\n","    TracIn,\n",")\n","from lfxai.explanations.features import attribute_auxiliary, attribute_individual_dim, tensor_attribution, attribute_training\n","from lfxai.models.images import (\n","    VAE,\n","    AutoEncoderMnist,\n","    ClassifierMnist,\n","    DecoderBurgess,\n","    DecoderMnist,\n","    EncoderBurgess,\n","    EncoderMnist,\n",")\n","from lfxai.models.losses import BetaHLoss, BtcvaeLoss, EntropyLoss, PearsonLoss\n","from lfxai.models.pretext import Identity, Mask, RandomNoise\n","from lfxai.utils.datasets import MaskedMNIST\n","from lfxai.utils.feature_attribution import generate_masks\n","from lfxai.utils.metrics import (\n","    compute_metrics,\n","    cos_saliency,\n","    count_activated_neurons,\n","    entropy_saliency_tensor,\n","    entropy_saliency,\n","    pearson_saliency,\n","    similarity_rates,\n","    spearman_saliency,\n","    pearson_saliency_tensor\n",")\n","from lfxai.utils.visualize import (\n","    correlation_latex_table,\n","    plot_pretext_saliencies,\n","    plot_pretext_top_example,\n","    plot_vae_saliencies,\n","    vae_box_plots,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tmAVmJ4Rbk-D"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"csufC4fnbk-D"},"outputs":[],"source":["W=32\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","data_dir = Path.cwd() / \"data/mnist\"\n","\n","img_size = (1, W, W)\n","encoder = EncoderBurgess(img_size, 3)\n","\n","baseline_image = torch.zeros((1, 1, W, W), device=device)\n","test_dataset = torchvision.datasets.MNIST(data_dir, train=False, download=True)\n","\n","\n","test_transform = transforms.Compose([transforms.Resize(W), transforms.ToTensor()])\n","test_dataset.transform = test_transform\n","test_dataset.data, test_dataset.targets = test_dataset.data[[1,2,3,4,5]], test_dataset.targets[[1,2,3,4,5]]\n","test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False)\n","\n","gradshap = GradientShap(encoder.mu)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_neD1JdSbk-D"},"outputs":[],"source":["saliency_tensor = tensor_attribution(encoder.mu, 3, test_loader, device, gradshap, baseline_image)\n","saliency_array = attribute_individual_dim(encoder.mu, 3, test_loader, device, gradshap, baseline_image)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4v0eFEx5bk-G"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FbJEHoPmbk-G"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"LMdpCNMZ5YvD","executionInfo":{"status":"ok","timestamp":1703046046808,"user_tz":-660,"elapsed":3,"user":{"displayName":"Harry Amad","userId":"02345983546097412963"}}},"outputs":[],"source":["def disvae_feature_importance(\n","    random_seed: int = 1,\n","    batch_size: int = 300,\n","    n_plots: int = 20,\n","    n_runs: int = 1,\n","    dim_latent: int = 3,\n","    n_epochs: int = 50,\n","    beta_list: list = [1],\n",") -> None:\n","    # Initialize seed and device\n","    np.random.seed(random_seed)\n","    torch.random.manual_seed(random_seed)\n","    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","    # Load MNIST\n","    W = 32\n","    img_size = (1, W, W)\n","    data_dir = Path.cwd() / \"drive/MyDrive/encoder_attribution_priors/experiments/data/mnist\"\n","    train_dataset = torchvision.datasets.MNIST(data_dir, train=True, download=True)\n","    test_dataset = torchvision.datasets.MNIST(data_dir, train=False, download=True)\n","    train_transform = transforms.Compose([transforms.Resize(W), transforms.ToTensor()])\n","    test_transform = transforms.Compose([transforms.Resize(W), transforms.ToTensor()])\n","    train_dataset.transform = train_transform\n","    test_dataset.transform = test_transform\n","    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n","    test_loader = torch.utils.data.DataLoader(\n","        test_dataset, batch_size=batch_size, shuffle=False\n","    )\n","\n","    # Create saving directory\n","    save_dir = Path.cwd() / \"drive/MyDrive/encoder_attribution_priors/experiments/results/mnist/vae\"\n","    if not save_dir.exists():\n","\n","        print(f\"Creating saving directory {save_dir}\")\n","        os.makedirs(save_dir)\n","\n","    # Define the computed metrics and create a csv file with appropriate headers\n","    loss_list = [BetaHLoss()]\n","    metric_list = [\n","        pearson_saliency,\n","        entropy_saliency,\n","        count_activated_neurons,\n","    ]\n","    metric_names = [\n","        \"Pearson Correlation\",\n","        \"Entropy\",\n","        \"Active Neurons\",\n","    ]\n","    headers = [\"Loss Type\", \"Beta\"] + metric_names\n","    csv_path = save_dir / \"metrics.csv\"\n","    if not csv_path.is_file():\n","        print(f\"Creating metrics csv in {csv_path}\")\n","\n","        with open(csv_path, \"w\") as csv_file:\n","            dw = csv.DictWriter(csv_file, delimiter=\",\", fieldnames=headers)\n","            dw.writeheader()\n","\n","    for beta, loss, run in itertools.product(\n","        beta_list, loss_list, range(1, n_runs + 1)\n","    ):\n","        # Initialize vaes\n","        encoder = EncoderBurgess(img_size, dim_latent)\n","        decoder = DecoderBurgess(img_size, dim_latent)\n","        loss.beta = beta\n","        name = f\"{str(loss)}-vae_beta{beta}_run{run}\"\n","        model = VAE(img_size, encoder, decoder, dim_latent, loss, name=name)\n","        print(f\"Now fitting {name}\")\n","\n","        model.fit(device, train_loader, test_loader, save_dir, n_epochs)\n","        model.load_state_dict(torch.load(save_dir / (name + \".pt\")), strict=False)\n","\n","        # Compute test-set saliency and associated metrics\n","        baseline_image = torch.zeros((1, 1, W, W), device=device)\n","        gradshap = GradientShap(encoder.mu)\n","        attributions = attribute_individual_dim(\n","            encoder.mu, dim_latent, test_loader, device, gradshap, baseline_image\n","        )\n","        metrics = compute_metrics(attributions, metric_list)\n","        results_str = \"\\t\".join(\n","            [f\"{metric_names[k]} {metrics[k]:.2g}\" for k in range(len(metric_list))]\n","        )\n","        print(f\"Model {name} \\t {results_str}\")\n","\n","\n","        # Save the metrics\n","        with open(csv_path, \"a\", newline=\"\") as csv_file:\n","            writer = csv.writer(csv_file, delimiter=\",\")\n","            writer.writerow([str(loss), beta] + metrics)\n","\n","        # Plot a couple of examples\n","        plot_idx = [\n","            torch.nonzero(test_dataset.targets == (n % 10))[n // 10].item()\n","            for n in range(n_plots)\n","        ]\n","        images_to_plot = [test_dataset[i][0].numpy().reshape(W, W) for i in plot_idx]\n","        fig = plot_vae_saliencies(images_to_plot, attributions[plot_idx])\n","        fig.savefig(save_dir / f\"{name}.pdf\")\n","        plt.close(fig)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":886413,"status":"ok","timestamp":1703046936541,"user":{"displayName":"Harry Amad","userId":"02345983546097412963"},"user_tz":-660},"id":"ziu2dJXK6KQx","outputId":"1e48aac9-d69e-4221-afc9-3071a24b6347"},"outputs":[{"output_type":"stream","name":"stdout","text":["Now fitting Beta-vae_beta1_run1\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50 \t \n","Train loss 303 \t Test loss 256 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 2/50 \t \n","Train loss 251 \t Test loss 246 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 3/50 \t \n","Train loss 245 \t Test loss 242 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 4/50 \t \n","Train loss 230 \t Test loss 223 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 5/50 \t \n","Train loss 219 \t Test loss 216 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 6/50 \t \n","Train loss 214 \t Test loss 212 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 7/50 \t \n","Train loss 211 \t Test loss 210 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 8/50 \t \n","Train loss 208 \t Test loss 206 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 9/50 \t \n","Train loss 205 \t Test loss 204 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 10/50 \t \n","Train loss 203 \t Test loss 203 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 11/50 \t \n","Train loss 202 \t Test loss 201 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 12/50 \t \n","Train loss 201 \t Test loss 201 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 13/50 \t \n","Train loss 200 \t Test loss 198 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 14/50 \t \n","Train loss 194 \t Test loss 190 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 15/50 \t \n","Train loss 190 \t Test loss 188 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 16/50 \t \n","Train loss 188 \t Test loss 186 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 17/50 \t \n","Train loss 186 \t Test loss 185 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 18/50 \t \n","Train loss 185 \t Test loss 184 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 19/50 \t \n","Train loss 184 \t Test loss 184 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 20/50 \t \n","Train loss 183 \t Test loss 182 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 21/50 \t \n","Train loss 183 \t Test loss 182 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 22/50 \t \n","Train loss 182 \t Test loss 181 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 23/50 \t \n","Train loss 182 \t Test loss 182 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 24/50 \t \n","Train loss 181 \t Test loss 181 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 25/50 \t \n","Train loss 181 \t Test loss 181 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 26/50 \t \n","Train loss 181 \t Test loss 181 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 27/50 \t \n","Train loss 180 \t Test loss 181 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 28/50 \t \n","Train loss 180 \t Test loss 181 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 29/50 \t \n","Train loss 180 \t Test loss 181 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 30/50 \t \n","Train loss 179 \t Test loss 180 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 31/50 \t \n","Train loss 179 \t Test loss 180 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 32/50 \t \n","Train loss 179 \t Test loss 180 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 33/50 \t \n","Train loss 179 \t Test loss 180 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 34/50 \t \n","Train loss 178 \t Test loss 179 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 35/50 \t \n","Train loss 178 \t Test loss 179 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 36/50 \t \n","Train loss 178 \t Test loss 180 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 37/50 \t \n","Train loss 178 \t Test loss 179 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 38/50 \t \n","Train loss 178 \t Test loss 178 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 39/50 \t \n","Train loss 178 \t Test loss 178 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 40/50 \t \n","Train loss 177 \t Test loss 178 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 41/50 \t \n","Train loss 177 \t Test loss 178 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 42/50 \t \n","Train loss 177 \t Test loss 178 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 43/50 \t \n","Train loss 177 \t Test loss 178 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 44/50 \t \n","Train loss 176 \t Test loss 178 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 45/50 \t \n","Train loss 176 \t Test loss 178 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 46/50 \t \n","Train loss 176 \t Test loss 178 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 47/50 \t \n","Train loss 176 \t Test loss 178 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 48/50 \t \n","Train loss 176 \t Test loss 177 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 49/50 \t \n","Train loss 176 \t Test loss 177 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 50/50 \t \n","Train loss 176 \t Test loss 177 \t \n","Model Beta-vae_beta1_run1 \t Pearson Correlation 0.27\tEntropy 0.69\tActive Neurons 1.3\n"]}],"source":["disvae_feature_importance()"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":764,"status":"ok","timestamp":1703047739771,"user":{"displayName":"Harry Amad","userId":"02345983546097412963"},"user_tz":-660},"id":"o3GTBTy1h5sS"},"outputs":[],"source":["def entropy_vae(\n","    random_seed: int = 1,\n","    batch_size: int = 300,\n","    n_plots: int = 20,\n","    n_runs: int = 1,\n","    dim_latent: int = 3,\n","    n_epochs: int = 50,\n","    alpha_list: list = [10],\n",") -> None:\n","    # Initialize seed and device\n","    np.random.seed(random_seed)\n","    torch.random.manual_seed(random_seed)\n","    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","    # Load MNIST\n","    W = 32\n","    img_size = (1, W, W)\n","    data_dir = Path.cwd() / \"drive/MyDrive/encoder_attribution_priors/experiments/data/mnist\"\n","    train_dataset = torchvision.datasets.MNIST(data_dir, train=True, download=True)\n","    #train_dataset.data, train_dataset.targets = train_dataset.data[[i for i in range(50)]], train_dataset.targets[[i for i in range(50)]]\n","    test_dataset = torchvision.datasets.MNIST(data_dir, train=False, download=True)\n","    #test_dataset.data, test_dataset.targets = test_dataset.data[[i for i in range(50)]], test_dataset.targets[[i for i in range(50)]]\n","    train_transform = transforms.Compose([transforms.Resize(W), transforms.ToTensor()])\n","    test_transform = transforms.Compose([transforms.Resize(W), transforms.ToTensor()])\n","    train_dataset.transform = train_transform\n","    test_dataset.transform = test_transform\n","    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n","    test_loader = torch.utils.data.DataLoader(\n","        test_dataset, batch_size=batch_size, shuffle=False\n","    )\n","\n","    # Create saving directory\n","    save_dir = Path.cwd() / \"drive/MyDrive/encoder_attribution_priors/experiments/results/mnist/entropy_vae\"\n","    if not save_dir.exists():\n","\n","        print(f\"Creating saving directory {save_dir}\")\n","        os.makedirs(save_dir)\n","\n","    # Define the computed metrics and create a csv file with appropriate headers\n","    loss_list = [EntropyLoss()]\n","    metric_list = [\n","        pearson_saliency,\n","        entropy_saliency,\n","        count_activated_neurons,\n","    ]\n","    metric_names = [\n","        \"Pearson Correlation\",\n","        \"Entropy\",\n","        \"Active Neurons\",\n","    ]\n","    headers = [\"Loss Type\", \"Alpha\"] + metric_names\n","    csv_path = save_dir / \"metrics.csv\"\n","    if not csv_path.is_file():\n","        print(f\"Creating metrics csv in {csv_path}\")\n","\n","        with open(csv_path, \"w\") as csv_file:\n","            dw = csv.DictWriter(csv_file, delimiter=\",\", fieldnames=headers)\n","            dw.writeheader()\n","\n","    for alpha, loss, run in itertools.product(\n","        alpha_list, loss_list, range(1, n_runs + 1)\n","    ):\n","        # Initialize vaes\n","        encoder = EncoderBurgess(img_size, dim_latent)\n","        decoder = DecoderBurgess(img_size, dim_latent)\n","        loss.alpha = alpha\n","        name = f\"{str(loss)}-vae_alpha{alpha}_run{run}\"\n","        model = VAE(img_size, encoder, decoder, dim_latent, loss, name=name)\n","        print(f\"Now fitting {name}\")\n","\n","        model.fit(device, train_loader, test_loader, save_dir, n_epochs)\n","        model.load_state_dict(torch.load(save_dir / (name + \".pt\")), strict=False)\n","\n","        # Compute test-set saliency and associated metrics\n","        baseline_image = torch.zeros((1, 1, W, W), device=device)\n","        gradshap = GradientShap(encoder.mu)\n","        attributions = attribute_individual_dim(\n","            encoder.mu, dim_latent, test_loader, device, gradshap, baseline_image\n","        )\n","        metrics = compute_metrics(attributions, metric_list)\n","        results_str = \"\\t\".join(\n","            [f\"{metric_names[k]} {metrics[k]:.2g}\" for k in range(len(metric_list))]\n","        )\n","        print(f\"Model {name} \\t {results_str}\")\n","\n","\n","        # Save the metrics\n","        with open(csv_path, \"a\", newline=\"\") as csv_file:\n","            writer = csv.writer(csv_file, delimiter=\",\")\n","            writer.writerow([str(loss), alpha] + metrics)\n","\n","        # Plot a couple of examples\n","        plot_idx = [\n","            torch.nonzero(test_dataset.targets == (n % 10))[n // 10].item()\n","            for n in range(n_plots)\n","        ]\n","        images_to_plot = [test_dataset[i][0].numpy().reshape(W, W) for i in plot_idx]\n","        fig = plot_vae_saliencies(images_to_plot, attributions[plot_idx])\n","        fig.savefig(save_dir / f\"{name}.pdf\")\n","        plt.close(fig)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":547},"executionInfo":{"elapsed":291158,"status":"error","timestamp":1703048034244,"user":{"displayName":"Harry Amad","userId":"02345983546097412963"},"user_tz":-660},"id":"B93_xB9piDY_","outputId":"349efb44-f40e-44ef-c8e1-b9fcf9d0c45a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Now fitting Entropy-vae_alpha10_run1\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50 \t \n","Train loss 0.0831 \t Test loss 0.0204 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 2/50 \t \n","Train loss 0.0122 \t Test loss 0.00708 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 3/50 \t \n","Train loss 0.00372 \t Test loss 0.0048 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 4/50 \t \n","Train loss 0.00197 \t Test loss 0.00215 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 5/50 \t \n","Train loss 0.00141 \t Test loss 0.000619 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 6/50 \t \n","Train loss 0.000908 \t Test loss 0.000218 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-e90ea7dc56e8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mentropy_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-8e1936bea700>\u001b[0m in \u001b[0;36mentropy_vae\u001b[0;34m(random_seed, batch_size, n_plots, n_runs, dim_latent, n_epochs, alpha_list)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Now fitting {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lfxai/models/images.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, device, train_loader, test_loader, save_dir, n_epoch, patience)\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0mbest_test_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m             \u001b[0;31m#logging.info(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lfxai/models/images.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, device, dataloader, optimizer)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"batches\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m             \u001b[0mimage_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mrecon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3101\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3103\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   3017\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_MAPMODES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3019\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3020\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m                 \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImagePalette\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["entropy_vae()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6X5Rl4jKbk-I"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QLGiY8J8bk-I"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":566,"status":"ok","timestamp":1703048079694,"user":{"displayName":"Harry Amad","userId":"02345983546097412963"},"user_tz":-660},"id":"cqoeN4Ohh5ui"},"outputs":[],"source":["def pearson_vae(\n","    random_seed: int = 1,\n","    batch_size: int = 300,\n","    n_plots: int = 20,\n","    n_runs: int = 1,\n","    dim_latent: int = 3,\n","    n_epochs: int = 50,\n","    alpha_list: list = [1],\n",") -> None:\n","    # Initialize seed and device\n","    np.random.seed(random_seed)\n","    torch.random.manual_seed(random_seed)\n","    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","    # Load MNIST\n","    W = 32\n","    img_size = (1, W, W)\n","    data_dir = Path.cwd() / \"drive/MyDrive/encoder_attribution_priors/experiments/data/mnist\"\n","    train_dataset = torchvision.datasets.MNIST(data_dir, train=True, download=True)\n","    #train_dataset.data, train_dataset.targets = train_dataset.data[[i for i in range(50)]], train_dataset.targets[[i for i in range(50)]]\n","    test_dataset = torchvision.datasets.MNIST(data_dir, train=False, download=True)\n","    #test_dataset.data, test_dataset.targets = test_dataset.data[[i for i in range(50)]], test_dataset.targets[[i for i in range(50)]]\n","    train_transform = transforms.Compose([transforms.Resize(W), transforms.ToTensor()])\n","    test_transform = transforms.Compose([transforms.Resize(W), transforms.ToTensor()])\n","    train_dataset.transform = train_transform\n","    test_dataset.transform = test_transform\n","    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n","    test_loader = torch.utils.data.DataLoader(\n","        test_dataset, batch_size=batch_size, shuffle=False\n","    )\n","\n","    # Create saving directory\n","    save_dir = Path.cwd() / \"drive/MyDrive/encoder_attribution_priors/experiments/results/mnist/pearson_vae\"\n","    if not save_dir.exists():\n","\n","        print(f\"Creating saving directory {save_dir}\")\n","        os.makedirs(save_dir)\n","\n","    # Define the computed metrics and create a csv file with appropriate headers\n","    loss_list = [PearsonLoss()]\n","    metric_list = [\n","        pearson_saliency,\n","        entropy_saliency,\n","        count_activated_neurons,\n","    ]\n","    metric_names = [\n","        \"Pearson Correlation\",\n","        \"Entropy\",\n","        \"Active Neurons\",\n","    ]\n","    headers = [\"Loss Type\", \"Alpha\"] + metric_names\n","    csv_path = save_dir / \"metrics.csv\"\n","    if not csv_path.is_file():\n","        print(f\"Creating metrics csv in {csv_path}\")\n","\n","        with open(csv_path, \"w\") as csv_file:\n","            dw = csv.DictWriter(csv_file, delimiter=\",\", fieldnames=headers)\n","            dw.writeheader()\n","\n","    for alpha, loss, run in itertools.product(\n","        alpha_list, loss_list, range(1, n_runs + 1)\n","    ):\n","        # Initialize vaes\n","        encoder = EncoderBurgess(img_size, dim_latent)\n","        decoder = DecoderBurgess(img_size, dim_latent)\n","        loss.alpha = alpha\n","        name = f\"{str(loss)}-vae_alpha{alpha}_run{run}\"\n","        model = VAE(img_size, encoder, decoder, dim_latent, loss, name=name)\n","        print(f\"Now fitting {name}\")\n","\n","        model.fit(device, train_loader, test_loader, save_dir, n_epochs)\n","        model.load_state_dict(torch.load(save_dir / (name + \".pt\")), strict=False)\n","\n","        # Compute test-set saliency and associated metrics\n","        baseline_image = torch.zeros((1, 1, W, W), device=device)\n","        gradshap = GradientShap(encoder.mu)\n","        attributions = attribute_individual_dim(\n","            encoder.mu, dim_latent, test_loader, device, gradshap, baseline_image\n","        )\n","        metrics = compute_metrics(attributions, metric_list)\n","        results_str = \"\\t\".join(\n","            [f\"{metric_names[k]} {metrics[k]:.2g}\" for k in range(len(metric_list))]\n","        )\n","        print(f\"Model {name} \\t {results_str}\")\n","\n","\n","        # Save the metrics\n","        with open(csv_path, \"a\", newline=\"\") as csv_file:\n","            writer = csv.writer(csv_file, delimiter=\",\")\n","            writer.writerow([str(loss), alpha] + metrics)\n","\n","        # Plot a couple of examples\n","        plot_idx = [\n","            torch.nonzero(test_dataset.targets == (n % 10))[n // 10].item()\n","            for n in range(n_plots)\n","        ]\n","        images_to_plot = [test_dataset[i][0].numpy().reshape(W, W) for i in plot_idx]\n","        fig = plot_vae_saliencies(images_to_plot, attributions[plot_idx])\n","        fig.savefig(save_dir / f\"{name}.pdf\")\n","        plt.close(fig)\n","\n","    fig = vae_box_plots(pd.read_csv(csv_path), metric_names, loss='entropy')\n","    fig.savefig(save_dir / \"metric_box_plots.pdf\")\n","    plt.close(fig)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"executionInfo":{"elapsed":49860,"status":"error","timestamp":1703048129552,"user":{"displayName":"Harry Amad","userId":"02345983546097412963"},"user_tz":-660},"id":"rZGVOjZuyxrT","outputId":"fb9a3279-d644-4e4d-f88a-257e113f00b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Now fitting Pearson-vae_alpha1_run1\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50 \t \n","Train loss 304 \t Test loss 256 \t \n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-2c1389a3f655>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpearson_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-16-10927d3d3eb6>\u001b[0m in \u001b[0;36mpearson_vae\u001b[0;34m(random_seed, batch_size, n_plots, n_runs, dim_latent, n_epochs, alpha_list)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Now fitting {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lfxai/models/images.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, device, train_loader, test_loader, save_dir, n_epoch, patience)\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0mbest_test_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m             \u001b[0;31m#logging.info(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lfxai/models/images.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, device, dataloader, optimizer)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"entropy\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'pearson'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 loss = self.loss_f(\n\u001b[0m\u001b[1;32m    921\u001b[0m                     \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0mrecon_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lfxai/models/losses.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, recon_batch, latent_dist, is_train, storer, encoder, latent_sample)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mbaseline_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mgradshap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientShap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mpearson_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pearson_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradshap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lfxai/models/losses.py\u001b[0m in \u001b[0;36m_pearson_loss\u001b[0;34m(encoder, dim_latent, data, device, gradshap, baseline_image)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_pearson_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradshap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m     \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_attribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradshap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m     \u001b[0mpearson_correlation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpearson_saliency_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lfxai/explanations/features.py\u001b[0m in \u001b[0;36mtensor_attribution\u001b[0;34m(encoder, dim_latent, data_loader, device, attr_method, baseline)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mlatents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_latent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mattribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattr_method\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mattributions_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mattributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/log/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/attr/_core/gradient_shap.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, baselines, n_samples, stdevs, target, additional_forward_args, return_convergence_delta)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;31m# NOTE: using attribute.__wrapped__ to not log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         attributions = nt.attribute.__wrapped__(\n\u001b[0m\u001b[1;32m    270\u001b[0m             \u001b[0mnt\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/attr/_core/noise_tunnel.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, nt_type, nt_samples, nt_samples_batch_size, stdevs, draw_baseline_from_distrib, **kwargs)\u001b[0m\n\u001b[1;32m    363\u001b[0m                     \u001b[0mis_attrib_tuple\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                     \u001b[0mdelta_partial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                 ) = compute_partial_attribution(inputs_with_noise, kwargs_copy)\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_attributions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/attr/_core/noise_tunnel.py\u001b[0m in \u001b[0;36mcompute_partial_attribution\u001b[0;34m(inputs_with_noise_partition, kwargs_partition)\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;31m# NOTE: using __wrapped__ such that it does not log the inner logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             attributions = attr_func.__wrapped__(  # type: ignore\n\u001b[0m\u001b[1;32m    254\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribution_method\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0minputs_with_noise_partition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/attr/_core/gradient_shap.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, return_convergence_delta)\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaselines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         )\n\u001b[0;32m--> 366\u001b[0;31m         grads = self.gradient_func(\n\u001b[0m\u001b[1;32m    367\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_baseline_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/_utils/gradient.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# torch.unbind(forward_out) is a list of scalar tensor tuples and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# contains batch_size * #steps elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0mgrad_outputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m     grad_outputs_ = _make_grads(\n\u001b[0m\u001b[1;32m    368\u001b[0m         \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_grads_batched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_grads_batched\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    125\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 new_grads.append(\n\u001b[0;32m--> 127\u001b[0;31m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                 )\n\u001b[1;32m    129\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["pearson_vae()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1702979731373,"user":{"displayName":"Harry Amad","userId":"02345983546097412963"},"user_tz":-660},"id":"xS3fL3kY1CpX","outputId":"138498e6-0092-40b8-8d1a-aefe239cfbec"},"outputs":[{"data":{"text/plain":["tensor(10., requires_grad=True)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["torch.tensor(10.0, requires_grad=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GMgQReuzfEIV"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"}},"nbformat":4,"nbformat_minor":0}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"149iS4S-4jg01oOsFNut57YoK9y3-RvPk","authorship_tag":"ABX9TyN5tyMcAuSbtrnfa0Y3xkMF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install captum\n","!pip install drive/MyDrive/encoder_attribution_priors/."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3XPm3DUU3yGb","executionInfo":{"status":"ok","timestamp":1702868355149,"user_tz":-660,"elapsed":23088,"user":{"displayName":"Harry Amad","userId":"02345983546097412963"}},"outputId":"5ae6c3cd-5d45-4945-bede-f06d7c1c8366"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: captum in /usr/local/lib/python3.10/dist-packages (0.7.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum) (1.23.5)\n","Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum) (2.1.0+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from captum) (4.66.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2.1.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.46.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->captum) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->captum) (1.3.0)\n","Processing ./drive/MyDrive/encoder_attribution_priors\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from lfxai==0.1.1) (2.1.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from lfxai==0.1.1) (0.16.0+cu121)\n","Requirement already satisfied: captum in /usr/local/lib/python3.10/dist-packages (from lfxai==0.1.1) (0.7.0)\n","Requirement already satisfied: hydra-core in /usr/local/lib/python3.10/dist-packages (from lfxai==0.1.1) (1.3.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lfxai==0.1.1) (1.23.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from lfxai==0.1.1) (1.5.3)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from lfxai==0.1.1) (0.19.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lfxai==0.1.1) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lfxai==0.1.1) (1.11.4)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from lfxai==0.1.1) (0.12.2)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from lfxai==0.1.1) (0.9.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lfxai==0.1.1) (4.66.1)\n","Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (from lfxai==0.1.1) (3.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lfxai==0.1.1) (3.7.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->lfxai==0.1.1) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->lfxai==0.1.1) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->lfxai==0.1.1) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->lfxai==0.1.1) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->lfxai==0.1.1) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->lfxai==0.1.1) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->lfxai==0.1.1) (2.1.0)\n","Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.10/dist-packages (from hydra-core->lfxai==0.1.1) (2.3.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core->lfxai==0.1.1) (4.9.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core->lfxai==0.1.1) (23.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lfxai==0.1.1) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lfxai==0.1.1) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lfxai==0.1.1) (4.46.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lfxai==0.1.1) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lfxai==0.1.1) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lfxai==0.1.1) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lfxai==0.1.1) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lfxai==0.1.1) (2023.3.post1)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->lfxai==0.1.1) (2.31.6)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->lfxai==0.1.1) (2023.12.9)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->lfxai==0.1.1) (1.5.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lfxai==0.1.1) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lfxai==0.1.1) (3.2.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->lfxai==0.1.1) (2.31.0)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.4,>=2.2->hydra-core->lfxai==0.1.1) (6.0.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lfxai==0.1.1) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->lfxai==0.1.1) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->lfxai==0.1.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->lfxai==0.1.1) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->lfxai==0.1.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->lfxai==0.1.1) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->lfxai==0.1.1) (1.3.0)\n","Building wheels for collected packages: lfxai\n","  Building wheel for lfxai (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lfxai: filename=lfxai-0.1.1-py3-none-any.whl size=30327 sha256=8ffc78f9481f633e8598f909dd50fe069208dd0fcb04a9ddd1003a592e7fe70b\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-8yskzhcy/wheels/7b/00/41/6fc986ab56840bbe22a1da3b92c41c9d55e2dcd851163270b7\n","Successfully built lfxai\n","Installing collected packages: lfxai\n","  Attempting uninstall: lfxai\n","    Found existing installation: lfxai 0.1.1\n","    Uninstalling lfxai-0.1.1:\n","      Successfully uninstalled lfxai-0.1.1\n","Successfully installed lfxai-0.1.1\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"z5BzCW00v06E","executionInfo":{"status":"ok","timestamp":1702868359571,"user_tz":-660,"elapsed":4426,"user":{"displayName":"Harry Amad","userId":"02345983546097412963"}}},"outputs":[],"source":["import argparse\n","import csv\n","import itertools\n","import logging\n","import os\n","from pathlib import Path\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import torch\n","import torchvision\n","from captum.attr import GradientShap, IntegratedGradients, Saliency\n","from scipy.stats import spearmanr\n","from torch.utils.data import DataLoader, RandomSampler, Subset\n","from torchvision import transforms\n","\n","from lfxai.explanations.examples import (\n","    InfluenceFunctions,\n","    NearestNeighbours,\n","    SimplEx,\n","    TracIn,\n",")\n","from lfxai.explanations.features import attribute_auxiliary, attribute_individual_dim\n","from lfxai.models.images import (\n","    VAE,\n","    AutoEncoderMnist,\n","    ClassifierMnist,\n","    DecoderBurgess,\n","    DecoderMnist,\n","    EncoderBurgess,\n","    EncoderMnist,\n",")\n","from lfxai.models.losses import BetaHLoss, BtcvaeLoss, EntropyLoss\n","from lfxai.models.pretext import Identity, Mask, RandomNoise\n","from lfxai.utils.datasets import MaskedMNIST\n","from lfxai.utils.feature_attribution import generate_masks\n","from lfxai.utils.metrics import (\n","    compute_metrics,\n","    cos_saliency,\n","    count_activated_neurons,\n","    entropy_saliency,\n","    pearson_saliency,\n","    similarity_rates,\n","    spearman_saliency,\n",")\n","from lfxai.utils.visualize import (\n","    correlation_latex_table,\n","    plot_pretext_saliencies,\n","    plot_pretext_top_example,\n","    plot_vae_saliencies,\n","    vae_box_plots,\n",")"]},{"cell_type":"code","source":["def disvae_feature_importance(\n","    random_seed: int = 1,\n","    batch_size: int = 300,\n","    n_plots: int = 20,\n","    #n_runs: int = 5,\n","    n_runs: int = 2,\n","    dim_latent: int = 3,\n","    #n_epochs: int = 100,\n","    n_epochs: int = 5,\n","    #beta_list: list = [1, 5, 10],\n","    beta_list: list = [1],\n",") -> None:\n","    # Initialize seed and device\n","    np.random.seed(random_seed)\n","    torch.random.manual_seed(random_seed)\n","    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","    # Load MNIST\n","    W = 32\n","    img_size = (1, W, W)\n","    data_dir = Path.cwd() / \"drive/MyDrive/encoder_attribution_priors/experiments/data/mnist\"\n","    train_dataset = torchvision.datasets.MNIST(data_dir, train=True, download=True)\n","    test_dataset = torchvision.datasets.MNIST(data_dir, train=False, download=True)\n","    train_transform = transforms.Compose([transforms.Resize(W), transforms.ToTensor()])\n","    test_transform = transforms.Compose([transforms.Resize(W), transforms.ToTensor()])\n","    train_dataset.transform = train_transform\n","    test_dataset.transform = test_transform\n","    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n","    test_loader = torch.utils.data.DataLoader(\n","        test_dataset, batch_size=batch_size, shuffle=False\n","    )\n","\n","    # Create saving directory\n","    save_dir = Path.cwd() / \"drive/MyDrive/encoder_attribution_priors/experiments/results/mnist/vae\"\n","    if not save_dir.exists():\n","\n","        print(f\"Creating saving directory {save_dir}\")\n","        os.makedirs(save_dir)\n","\n","    # Define the computed metrics and create a csv file with appropriate headers\n","    loss_list = [EntropyLoss(alpha=100), BetaHLoss(), BtcvaeLoss(is_mss=False, n_data=len(train_dataset))]\n","    metric_list = [\n","        pearson_saliency,\n","        spearman_saliency,\n","        cos_saliency,\n","        entropy_saliency,\n","        count_activated_neurons,\n","    ]\n","    metric_names = [\n","        \"Pearson Correlation\",\n","        \"Spearman Correlation\",\n","        \"Cosine\",\n","        \"Entropy\",\n","        \"Active Neurons\",\n","    ]\n","    headers = [\"Loss Type\", \"Beta\"] + metric_names\n","    csv_path = save_dir / \"metrics.csv\"\n","    if not csv_path.is_file():\n","        print(f\"Creating metrics csv in {csv_path}\")\n","\n","        with open(csv_path, \"w\") as csv_file:\n","            dw = csv.DictWriter(csv_file, delimiter=\",\", fieldnames=headers)\n","            dw.writeheader()\n","\n","    for beta, loss, run in itertools.product(\n","        beta_list, loss_list, range(1, n_runs + 1)\n","    ):\n","        # Initialize vaes\n","        encoder = EncoderBurgess(img_size, dim_latent)\n","        decoder = DecoderBurgess(img_size, dim_latent)\n","        loss.beta = beta\n","        name = f\"{str(loss)}-vae_beta{beta}_run{run}\"\n","        model = VAE(img_size, encoder, decoder, dim_latent, loss, name=name)\n","        print(f\"Now fitting {name}\")\n","\n","        model.fit(device, train_loader, test_loader, save_dir, n_epochs)\n","        model.load_state_dict(torch.load(save_dir / (name + \".pt\")), strict=False)\n","\n","        # Compute test-set saliency and associated metrics\n","        baseline_image = torch.zeros((1, 1, W, W), device=device)\n","        gradshap = GradientShap(encoder.mu)\n","        attributions = attribute_individual_dim(\n","            encoder.mu, dim_latent, test_loader, device, gradshap, baseline_image\n","        )\n","        metrics = compute_metrics(attributions, metric_list)\n","        results_str = \"\\t\".join(\n","            [f\"{metric_names[k]} {metrics[k]:.2g}\" for k in range(len(metric_list))]\n","        )\n","        print(f\"Model {name} \\t {results_str}\")\n","\n","\n","        # Save the metrics\n","        with open(csv_path, \"a\", newline=\"\") as csv_file:\n","            writer = csv.writer(csv_file, delimiter=\",\")\n","            writer.writerow([str(loss), beta] + metrics)\n","\n","        # Plot a couple of examples\n","        plot_idx = [\n","            torch.nonzero(test_dataset.targets == (n % 10))[n // 10].item()\n","            for n in range(n_plots)\n","        ]\n","        images_to_plot = [test_dataset[i][0].numpy().reshape(W, W) for i in plot_idx]\n","        fig = plot_vae_saliencies(images_to_plot, attributions[plot_idx])\n","        fig.savefig(save_dir / f\"{name}.pdf\")\n","        plt.close(fig)\n","\n","    fig = vae_box_plots(pd.read_csv(csv_path), metric_names)\n","    fig.savefig(save_dir / \"metric_box_plots.pdf\")\n","    plt.close(fig)"],"metadata":{"id":"LMdpCNMZ5YvD","executionInfo":{"status":"ok","timestamp":1702868359571,"user_tz":-660,"elapsed":4,"user":{"displayName":"Harry Amad","userId":"02345983546097412963"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["disvae_feature_importance()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ziu2dJXK6KQx","executionInfo":{"status":"ok","timestamp":1702869670095,"user_tz":-660,"elapsed":1310527,"user":{"displayName":"Harry Amad","userId":"02345983546097412963"}},"outputId":"7ad1bf5a-9d64-4432-e027-f9f596dea0bb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Now fitting Entropy-vae_beta1_run1\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Model Entropy-vae_beta1_run1 \t Pearson Correlation 0.52\tSpearman Correlation 0.99\tCosine 0.82\tEntropy 0.066\tActive Neurons 1\n","Now fitting Entropy-vae_beta1_run2\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Model Entropy-vae_beta1_run2 \t Pearson Correlation 0.38\tSpearman Correlation 0.99\tCosine 0.73\tEntropy 0.22\tActive Neurons 1\n","Now fitting Beta-vae_beta1_run1\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Model Beta-vae_beta1_run1 \t Pearson Correlation 0.42\tSpearman Correlation 0.99\tCosine 0.73\tEntropy 0.45\tActive Neurons 1.3\n","Now fitting Beta-vae_beta1_run2\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Model Beta-vae_beta1_run2 \t Pearson Correlation 0.33\tSpearman Correlation 0.98\tCosine 0.62\tEntropy 0.74\tActive Neurons 1.3\n","Now fitting TC-vae_beta1_run1\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Model TC-vae_beta1_run1 \t Pearson Correlation 0.31\tSpearman Correlation 0.99\tCosine 0.63\tEntropy 0.74\tActive Neurons 1.3\n","Now fitting TC-vae_beta1_run2\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Model TC-vae_beta1_run2 \t Pearson Correlation 0.31\tSpearman Correlation 0.98\tCosine 0.61\tEntropy 0.72\tActive Neurons 1.3\n"]}]},{"cell_type":"code","source":["W = 32\n","img_size = (1, W, W)\n","data_dir = Path.cwd() / \"drive/MyDrive/encoder_attribution_priors/experiments/data/mnist\"\n","\n","test_dataset = torchvision.datasets.MNIST(data_dir, train=False, download=True)\n","\n","test_transform = transforms.Compose([transforms.Resize(W), transforms.ToTensor()])\n","\n","test_dataset.transform = test_transform\n","\n","test_loader = torch.utils.data.DataLoader(\n","    test_dataset, batch_size=10000, shuffle=False\n",")"],"metadata":{"id":"B74lqmSN7H1I","executionInfo":{"status":"ok","timestamp":1702869670096,"user_tz":-660,"elapsed":4,"user":{"displayName":"Harry Amad","userId":"02345983546097412963"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["[i for i in torch.utils.data.DataLoader(test_dataset, batch_size=10000, shuffle=False)]"],"metadata":{"id":"mIq-Xwt-TgI0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702869671803,"user_tz":-660,"elapsed":1710,"user":{"displayName":"Harry Amad","userId":"02345983546097412963"}},"outputId":"53cfdf65-3be2-4298-e2e8-cdb8126c98aa"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n","            [0., 0., 0.,  ..., 0., 0., 0.],\n","            [0., 0., 0.,  ..., 0., 0., 0.],\n","            ...,\n","            [0., 0., 0.,  ..., 0., 0., 0.],\n","            [0., 0., 0.,  ..., 0., 0., 0.],\n","            [0., 0., 0.,  ..., 0., 0., 0.]]],\n","  \n","  \n","          [[[0., 0., 0.,  ..., 0., 0., 0.],\n","            [0., 0., 0.,  ..., 0., 0., 0.],\n","            [0., 0., 0.,  ..., 0., 0., 0.],\n","            ...,\n","            [0., 0., 0.,  ..., 0., 0., 0.],\n","            [0., 0., 0.,  ..., 0., 0., 0.],\n","            [0., 0., 0.,  ..., 0., 0., 0.]]],\n","  \n","  \n","          [[[0., 0., 0.,  ..., 0., 0., 0.],\n","            [0., 0., 0.,  ..., 0., 0., 0.],\n","            [0., 0., 0.,  ..., 0., 0., 0.],\n","            ...,\n","            [0., 0., 0.,  ..., 0., 0., 0.],\n","            [0., 0., 0.,  ..., 0., 0., 0.],\n","            [0., 0., 0.,  ..., 0., 0., 0.]]],\n","  \n","  \n","          ...,\n","  \n","  \n","          [[[0., 0., 0.,  ..., 0., 0., 0.],\n","            [0., 0., 0.,  ..., 0., 0., 0.],\n","            [0., 0., 0.,  ..., 0., 0., 0.],\n","            ...,\n","            [0., 0., 0.,  ..., 0., 0., 0.],\n","            [0., 0., 0.,  ..., 0., 0., 0.],\n","            [0., 0., 0.,  ..., 0., 0., 0.]]],\n","  \n","  \n","          [[[0., 0., 0.,  ..., 0., 0., 0.],\n","            [0., 0., 0.,  ..., 0., 0., 0.],\n","            [0., 0., 0.,  ..., 0., 0., 0.],\n","            ...,\n","            [0., 0., 0.,  ..., 0., 0., 0.],\n","            [0., 0., 0.,  ..., 0., 0., 0.],\n","            [0., 0., 0.,  ..., 0., 0., 0.]]],\n","  \n","  \n","          [[[0., 0., 0.,  ..., 0., 0., 0.],\n","            [0., 0., 0.,  ..., 0., 0., 0.],\n","            [0., 0., 0.,  ..., 0., 0., 0.],\n","            ...,\n","            [0., 0., 0.,  ..., 0., 0., 0.],\n","            [0., 0., 0.,  ..., 0., 0., 0.],\n","            [0., 0., 0.,  ..., 0., 0., 0.]]]]),\n","  tensor([7, 2, 1,  ..., 4, 5, 6])]]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["torch.Size([300, 1, 32, 32])[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfcZxcmnv6R3","executionInfo":{"status":"ok","timestamp":1702869671803,"user_tz":-660,"elapsed":10,"user":{"displayName":"Harry Amad","userId":"02345983546097412963"}},"outputId":"96094aa5-e9e9-4514-f69c-9846b7810b1f"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["300"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["test_dataset.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"id":"nxpAzU4VyRYB","executionInfo":{"status":"error","timestamp":1702869671803,"user_tz":-660,"elapsed":9,"user":{"displayName":"Harry Amad","userId":"02345983546097412963"}},"outputId":"ec8a2833-3511-464c-f9b0-33ff8b84ac49"},"execution_count":8,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-5ae17639885c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'MNIST' object has no attribute 'size'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"rZGVOjZuyxrT","executionInfo":{"status":"aborted","timestamp":1702869671804,"user_tz":-660,"elapsed":8,"user":{"displayName":"Harry Amad","userId":"02345983546097412963"}}},"execution_count":null,"outputs":[]}]}